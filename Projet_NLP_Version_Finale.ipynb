{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t6_tEx4e_HhS"
   },
   "source": [
    "# **TripAdvisor Hotel Reviews**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6s5gujua-QiV"
   },
   "source": [
    "## Importation des biblioth√©ques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TPeG3lea8va3"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.tag import UnigramTagger\n",
    "from nltk.corpus import treebank\n",
    "import nltk\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "replacement_patterns = [\n",
    "    (r'won\\'t', 'will not'),\n",
    "    (r'can\\'t', 'cannot'),\n",
    "    (r'i\\'m', 'i am'),\n",
    "    (r'ain\\'t', 'is not'),\n",
    "    (r'(\\w+)\\'ll', '\\g<1> will'),\n",
    "    (r'(\\w+)n\\'t', '\\g<1> not'),\n",
    "    (r'(\\w+)\\'ve', '\\g<1> have'),\n",
    "    (r'(\\w+)\\'s', '\\g<1> is'),\n",
    "    (r'(\\w+)\\'re', '\\g<1> are'),\n",
    "    (r'(\\w+)\\'d', '\\g<1> would'),\n",
    "]\n",
    "\n",
    "class RegexpReplacer(object):\n",
    "    def __init__(self, patterns=replacement_patterns): \n",
    "        self.patterns = [(re.compile(regex), repl) for (regex, repl) in patterns]\n",
    "    def replace(self, text):\n",
    "        s = text\n",
    "        for (pattern, repl) in self.patterns:\n",
    "            s = re.sub(pattern, repl, s) \n",
    "        return s\n",
    "\n",
    "replacer=RegexpReplacer()\n",
    "replacer.replace(\"Don't hesistate to ask questions\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import math\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from pprint import pprint\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import string\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import nltk\n",
    "\n",
    "# Prevent future/deprecation warnings from showing in output\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from bs4 import BeautifulSoup             \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from nltk.corpus import stopwords \n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score, roc_curve\n",
    "\n",
    "#Visualization packages\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "jXYsyLQI-BqI",
    "outputId": "8f81fc62-df91-46da-a2e9-953049769610"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/treebank.zip.\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('treebank')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EYx_aZRS-W-E"
   },
   "source": [
    "## Importation du dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oXz9776e81WM"
   },
   "outputs": [],
   "source": [
    "#file_id='1DiCkP6qwCxIPK2TuK47US_QTVEminv5T'\n",
    "#link='https://drive.google.com/uc?export=download&id={FILE_ID}'\n",
    "#csv_url=link.format(FILE_ID=file_id)\n",
    "\n",
    "#original_dataset = pd.read_csv(csv_url, sep=';', index_col='Unnamed: 0')\n",
    "\n",
    "column_names = ['reviews.rating','reviews.text']\n",
    "original_dataset = pd.read_csv('http://christophe-rodrigues.fr/eval_reviews.csv', usecols=column_names, sep=\";\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "zMSdDIE2Z5Dg",
    "outputId": "fbfa6e9c-f7ed-42f3-b232-16595be2ca03"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews.rating</th>\n",
       "      <th>reviews.text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>This hotel was nice and quiet. Did not know, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>We stayed in the king suite with the separatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Parking was horrible, somebody ran into my ren...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Not cheap but excellent location. Price is som...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>If you get the room that they advertised on th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   reviews.rating                                       reviews.text\n",
       "0               3  This hotel was nice and quiet. Did not know, t...\n",
       "1               4  We stayed in the king suite with the separatio...\n",
       "2               3  Parking was horrible, somebody ran into my ren...\n",
       "3               5  Not cheap but excellent location. Price is som...\n",
       "4               2  If you get the room that they advertised on th..."
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "HvKj4CRc85lk",
    "outputId": "fa4bfcb7-5e82-4250-a477-390fc7c2418f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dimension du dataset\n",
    "original_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "colab_type": "code",
    "id": "WDKYdaUIAE_w",
    "outputId": "ae51ae27-6765-41a4-acf8-cf3406df1b30"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews.rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.084100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.152371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviews.rating\n",
       "count    10000.000000\n",
       "mean         4.084100\n",
       "std          1.152371\n",
       "min          1.000000\n",
       "25%          4.000000\n",
       "50%          4.000000\n",
       "75%          5.000000\n",
       "max          5.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_dataset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fljeOpG7AmqG"
   },
   "source": [
    "Regardons le nombre de valeurs manquantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "t0dxkzu0AGzD",
    "outputId": "06d901a7-0017-42fa-8858-1c4e1d4f63f5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reviews.rating    0\n",
       "reviews.text      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_dataset.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i88jdcI9A3_s"
   },
   "source": [
    "##### Supprimons tous les MoreMore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "827DAm7uAMT8"
   },
   "outputs": [],
   "source": [
    "original_dataset = original_dataset[original_dataset['reviews.text']!='MoreMore']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "3g3SXwFAAQZe",
    "outputId": "04caddf5-1dd1-4c85-d21f-9f1c23e370a3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9982, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OGUkSvU7A9iX"
   },
   "source": [
    "### Regardons la distribution des diff√©rentes notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "lU3ph58QA_r0",
    "outputId": "b21f44b5-6d47-4fed-81a4-642f1106f81c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    4837\n",
       "4    2844\n",
       "3    1184\n",
       "1     564\n",
       "2     553\n",
       "Name: reviews.rating, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_dataset['reviews.rating'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DXcyRGH5BJWX"
   },
   "source": [
    "On peut voir que la r√©partition est d√©s√©quilibr√©e et qu'il y a une tr√®s grosse partie de 5 contrairement √† la note 1 et 2. Les avis sont donc positifs dans la majorit√©\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "colab_type": "code",
    "id": "GrfKGhXvE3Ei",
    "outputId": "2ea110fe-2636-4a19-ff12-aa3acaf343e6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f72046e78d0>"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD1CAYAAAC87SVQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nR80AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "original_dataset['reviews.rating'].value_counts().plot.bar(color='blue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z2wAtz4BBq5r"
   },
   "source": [
    "### Fonction de preprocessing pour les reviews. Nous allons passer par les differentes etapes afin de nettoyer de la meilleure maniere les reviews.\n",
    "- Convert the text to lowercase\n",
    "- Removing Numbers\n",
    "- Removing white spaces\n",
    "- Replacer replace\n",
    "- Tokenize into sentences\n",
    "- Tokenize into words\n",
    "- Remove stop words\n",
    "- Lemmatize\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ukz21yL1BCou"
   },
   "outputs": [],
   "source": [
    " \n",
    "def preprocess_text(test):\n",
    "\n",
    "    #Convert the text to lowercase\n",
    "    test = test.lower()\n",
    "\n",
    "    #Removing Numbers\n",
    "    test=re.sub(r'\\d+','',test)\n",
    "\n",
    "\n",
    "    \n",
    "    #Removing white spaces\n",
    "    test=test.strip()\n",
    "    \n",
    "    #Replacer replace\n",
    "    text_replaced = replacer.replace(test)\n",
    "    \n",
    "\n",
    "    \n",
    "    #Tokenize\n",
    "    tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "    sentences = tokenizer.tokenize(text_replaced)\n",
    "\n",
    "    #Tokenize words\n",
    "    from nltk.tokenize import RegexpTokenizer\n",
    "    tokenizer=RegexpTokenizer(\"[\\w]+\")\n",
    "\n",
    "    for i in range(len(sentences)):\n",
    "        sentences[i] = tokenizer.tokenize(sentences[i])\n",
    "\n",
    "    #Remove stop words\n",
    "\n",
    "    from nltk.corpus import stopwords\n",
    "    stops=set(stopwords.words('english'))\n",
    "\n",
    "    for i in range(len(sentences)):\n",
    "        sentences[i] = [word for word in sentences[i] if word not in stops]\n",
    "\n",
    "    #Lemmatize\n",
    "\n",
    "    from nltk.stem import WordNetLemmatizer\n",
    "    lemmatizer_output=WordNetLemmatizer()\n",
    "\n",
    "    for i in range(len(sentences)):\n",
    "        for j in range(len(sentences[i])):\n",
    "            sentences[i][j] = lemmatizer_output.lemmatize(sentences[i][j])\n",
    "\n",
    "\n",
    "    #Join the words back into a sentence.\n",
    "    a=[' '.join(s) for s in sentences]\n",
    "    b=['. '.join(a)]\n",
    "\n",
    "    return b \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6-Eo-T-2B2WO"
   },
   "source": [
    "#### Appliquons cette fonction sur les reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P4SPLvXoBv3S"
   },
   "outputs": [],
   "source": [
    "review_clean = [preprocess_text(doc) for doc in original_dataset['reviews.text']]\n",
    "sentences = [' '.join(r) for r in review_clean]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ot5uBnxCA-PU"
   },
   "source": [
    "Cr√©ation d'une colonne avec les reviews nettoy√©s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "iC9YKQxIB-SN",
    "outputId": "c1e71faa-5a7b-422d-c780-5c4ce12ab0d0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews.rating</th>\n",
       "      <th>reviews.text</th>\n",
       "      <th>text_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>This hotel was nice and quiet. Did not know, t...</td>\n",
       "      <td>hotel nice quiet. know train track near. train...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>We stayed in the king suite with the separatio...</td>\n",
       "      <td>stayed king suite separation bedroom living sp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Parking was horrible, somebody ran into my ren...</td>\n",
       "      <td>parking horrible somebody ran rental car stayi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Not cheap but excellent location. Price is som...</td>\n",
       "      <td>cheap excellent location. price somewhat stand...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>If you get the room that they advertised on th...</td>\n",
       "      <td>get room advertised website paid may lucky sta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   reviews.rating  ...                                       text_cleaned\n",
       "0               3  ...  hotel nice quiet. know train track near. train...\n",
       "1               4  ...  stayed king suite separation bedroom living sp...\n",
       "2               3  ...  parking horrible somebody ran rental car stayi...\n",
       "3               5  ...  cheap excellent location. price somewhat stand...\n",
       "4               2  ...  get room advertised website paid may lucky sta...\n",
       "\n",
       "[5 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_dataset['text_cleaned']=sentences\n",
    "original_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rRNQv5aYD-rL"
   },
   "source": [
    "### Nous allons faire une copie du dataset dans le but d'essayer une premiere approche binaire\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a5KbPNZ5D-Mf"
   },
   "outputs": [],
   "source": [
    "dataset = original_dataset.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7ztH69bVEG2B"
   },
   "source": [
    "### Nous appliquons le principe suivant pour pouvoir avoir un modele binaire \n",
    "- Si la note est inferieure √† 3 alors la note devient 0\n",
    "- Autrement la note devient 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G8IGpj0lCUEE"
   },
   "outputs": [],
   "source": [
    "dataset[dataset['reviews.rating'] != 3]\n",
    "dataset['labels'] = np.where(dataset['reviews.rating'] > 2, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "WuNPiGKmENoJ",
    "outputId": "9e7554bd-7b10-4c8f-f6f2-fb3e82047b7c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews.rating</th>\n",
       "      <th>reviews.text</th>\n",
       "      <th>text_cleaned</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>This hotel was nice and quiet. Did not know, t...</td>\n",
       "      <td>hotel nice quiet. know train track near. train...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>We stayed in the king suite with the separatio...</td>\n",
       "      <td>stayed king suite separation bedroom living sp...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Parking was horrible, somebody ran into my ren...</td>\n",
       "      <td>parking horrible somebody ran rental car stayi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Not cheap but excellent location. Price is som...</td>\n",
       "      <td>cheap excellent location. price somewhat stand...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>If you get the room that they advertised on th...</td>\n",
       "      <td>get room advertised website paid may lucky sta...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   reviews.rating  ... labels\n",
       "0               3  ...      1\n",
       "1               4  ...      1\n",
       "2               3  ...      1\n",
       "3               5  ...      1\n",
       "4               2  ...      0\n",
       "\n",
       "[5 rows x 4 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O3WOwgDdEh5z"
   },
   "source": [
    "## Regardons la r√©partition des notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "2tHobhaPEPAB",
    "outputId": "25a2172c-d7ac-45fa-9fa6-2aa3570ee102"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    8865\n",
       "0    1117\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['labels'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "colab_type": "code",
    "id": "NRB138-BEmWK",
    "outputId": "1861580d-74ee-4307-e12a-7f869abc1aa2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f71ffef7f98>"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD1CAYAAAC87SVQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nnl3Mo07dlsMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset['labels'].value_counts().plot.bar(color='green')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W5klujb0FY6b"
   },
   "source": [
    "###### Nous allons donc utilis√© un modele de classification pour pr√©dire la classe 0 ou 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qbrcEa4mMtEY"
   },
   "source": [
    "*Nous allons split le dataset en training et test*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ARTrUrhAFX_b"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = dataset.text_cleaned\n",
    "y = dataset.labels\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XVoepJ4fFrZb"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(max_features=15000, binary=True)\n",
    "\n",
    "X_train_vect = vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qVG7ET_sQXxp"
   },
   "outputs": [],
   "source": [
    "#Utilisation de smote pour les dataset d√©s√©quilibr√©s\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "sm = SMOTE()\n",
    "\n",
    "X_train_res, y_train_res = sm.fit_sample(X_train_vect, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YWUxFGtlS2Iy"
   },
   "outputs": [],
   "source": [
    "X_test_vect = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-u9-znpPCoF6"
   },
   "source": [
    "#### Utilisation du modele Naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oQRZvtirSVW4"
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nb = MultinomialNB()\n",
    "\n",
    "nb.fit(X_train_res, y_train_res)\n",
    "\n",
    "y_pred = nb.predict(X_test_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "sNbA7eOgQXtH",
    "outputId": "9648fa38-a221-4662-8150-ce0c3baa64f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 92.74%\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: {:.2f}%\".format(accuracy_score(y_test, y_pred) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RSJMuDbmC2Ti"
   },
   "source": [
    "Faisons quelques tests sur differentes phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "kK3_ciKvQXrJ",
    "outputId": "cf56ee66-c1e4-4b1b-ebdb-cbb6d9287d2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "print(nb.predict(vectorizer.transform(['this hotel was amazing'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "d15qXMijQXoh",
    "outputId": "3e390895-9376-4daa-c03e-8d29df3c577d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "print(nb.predict(vectorizer.transform(['This hotel was a fucking joke, have you ever seen a housekipper that doesn\\'t clean room? '])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "snWfsyRwYltL"
   },
   "source": [
    "Cependant nous voulons pr√©dire les notes et non une classe binaire.\n",
    "\n",
    "Apres avoir tester un modele binaire nous allons complexifier cela en passant avec les vrai notes et non les labels binaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "WO30O_b7Ykgl",
    "outputId": "35887940-6a31-4ec6-b811-0a82418bec00"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews.rating</th>\n",
       "      <th>reviews.text</th>\n",
       "      <th>text_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>This hotel was nice and quiet. Did not know, t...</td>\n",
       "      <td>hotel nice quiet. know train track near. train...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>We stayed in the king suite with the separatio...</td>\n",
       "      <td>stayed king suite separation bedroom living sp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Parking was horrible, somebody ran into my ren...</td>\n",
       "      <td>parking horrible somebody ran rental car stayi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Not cheap but excellent location. Price is som...</td>\n",
       "      <td>cheap excellent location. price somewhat stand...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>If you get the room that they advertised on th...</td>\n",
       "      <td>get room advertised website paid may lucky sta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   reviews.rating  ...                                       text_cleaned\n",
       "0               3  ...  hotel nice quiet. know train track near. train...\n",
       "1               4  ...  stayed king suite separation bedroom living sp...\n",
       "2               3  ...  parking horrible somebody ran rental car stayi...\n",
       "3               5  ...  cheap excellent location. price somewhat stand...\n",
       "4               2  ...  get room advertised website paid may lucky sta...\n",
       "\n",
       "[5 rows x 3 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2OYNeUZ3Ys7v"
   },
   "outputs": [],
   "source": [
    "x1 = original_dataset['text_cleaned']\n",
    "y1 = original_dataset['reviews.rating']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CrjqWV74ZEtx"
   },
   "source": [
    "Nous allons creer un vectorizer pour split le text en unigram et bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IF3V_WeRZD0b"
   },
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(ngram_range = (1,2))\n",
    "x_vect1 = vect.fit_transform(x1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "smFPCOLuZep0"
   },
   "source": [
    "### Nous allons split le dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lo1xqY_nZMqO"
   },
   "outputs": [],
   "source": [
    "x_train_c, x_test_c, y_train_c, y_test_c = train_test_split(x_vect1, y1, test_size=0.15, random_state = 10, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xCDoJOZlZmry"
   },
   "source": [
    "### Linear SVM pour une classification multiclasse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "MS07H9vZZh1o",
    "outputId": "22bb3149-c11a-44ca-c627-703033f0df1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVC: 0.5961281708945261\n",
      "MSE:  1.0580774365821095\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "lin_svc_mod = LinearSVC(C=0.13, class_weight=None, dual=True, fit_intercept=True,\n",
    "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
    "     multi_class='ovr', penalty='l2', random_state=0, tol=1e-05, verbose=0)\n",
    "lin_svc_mod.fit(x_train_c, y_train_c)\n",
    "pred = lin_svc_mod.predict(x_test_c)\n",
    "print(\"Linear SVC:\",accuracy_score(y_test_c, pred))\n",
    "print(\"MSE: \",mean_squared_error(y_test_c,pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "E-LtcO8bhljI",
    "outputId": "720e970b-922a-49d2-8949-1b3e1b820d52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "print(lin_svc_mod.predict(vect.transform(['this hotel was horrible'])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1FyVTvt4D0wH"
   },
   "source": [
    "Prenons une phrase d'une review qui n'apparait pas dans le dataset et qui a √©galement √©t√© not√© sur TipAdvisor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "Tqztl_JFhRXg",
    "outputId": "ff2270e0-2bc5-414c-e727-384d47c0add2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score suppos√© : 4\n",
      "Score predit : \n",
      "[5]\n"
     ]
    }
   ],
   "source": [
    "print(\"Score suppos√© : 4\")\n",
    "print(\"Score predit : \")\n",
    "print(lin_svc_mod.predict(vect.transform(['loved \tstayed warwick overnight getway enjoy christmas shopping \twarwick exceeded expectations \tstaff wonderful extrememly friendly room clean service lounge wonderful \tcame contact hotel friendly \twomen bathroom lever lounge well.. think haunted totally creepy vibe lights anywho \treally enjoyed stay going couple days \t '])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8exHeVvSFV3D"
   },
   "source": [
    "On s'approche de la classe d√©sir√©, en effet notre mod√©le a une pr√©cision de 60%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "usTzv-BZbqJm",
    "outputId": "ba0b203b-a445-4105-9f99-f8d1c17abfd8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 53.67\n",
      "MSE:  1.341789052069426\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rmfr = RandomForestClassifier()\n",
    "rmfr.fit(x_train_c, y_train_c)\n",
    "predrmfr = rmfr.predict(x_test_c)\n",
    "print(\"Score:\",round(accuracy_score(y_test_c,predrmfr)*100,2))\n",
    "print(\"MSE: \",mean_squared_error(y_test_c,predrmfr))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "olHPeK7_F0Ga"
   },
   "source": [
    "Faisons un grid search pour savoir quelle sont les meilleurs parametres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "colab_type": "code",
    "id": "n0C94znDKEGV",
    "outputId": "843e0271-7fc5-4ce4-9808-01581ee236b2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators=10, n_jobs=None,\n",
       "                                              oob_score=False,\n",
       "                                              random_state=None, verbose=0,\n",
       "                                              warm_start=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'max_depth': [2, 4, 8, 16, 32, 64],\n",
       "                         'n_estimators': [5, 10, 50, 100, 250]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 36,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "parameters = {\n",
    "    \"n_estimators\":[5,10,50,100,250],\n",
    "    \"max_depth\":[2,4,8,16,32,64]\n",
    "    \n",
    "}\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "cv = GridSearchCV(rmfr,parameters,cv=5)\n",
    "cv.fit(x_train_c, y_train_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OrF72qvUNXrC"
   },
   "outputs": [],
   "source": [
    "def display(results):\n",
    "    print(f'Best parameters are: {results.best_params_}')\n",
    "    print(\"\\n\")\n",
    "    mean_score = results.cv_results_['mean_test_score']\n",
    "    std_score = results.cv_results_['std_test_score']\n",
    "    params = results.cv_results_['params']\n",
    "    for mean,std,params in zip(mean_score,std_score,params):\n",
    "        print(f'{round(mean,3)} + or -{round(std,3)} for the {params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 578
    },
    "colab_type": "code",
    "id": "H_EFiwk-NgOA",
    "outputId": "2f2ec0d1-209b-49c6-f18c-e854b0bc7524"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters are: {'max_depth': 64, 'n_estimators': 10}\n",
      "\n",
      "\n",
      "0.483 + or -0.001 for the {'max_depth': 2, 'n_estimators': 5}\n",
      "0.483 + or -0.0 for the {'max_depth': 2, 'n_estimators': 10}\n",
      "0.483 + or -0.0 for the {'max_depth': 2, 'n_estimators': 50}\n",
      "0.483 + or -0.0 for the {'max_depth': 2, 'n_estimators': 100}\n",
      "0.483 + or -0.0 for the {'max_depth': 2, 'n_estimators': 250}\n",
      "0.483 + or -0.001 for the {'max_depth': 4, 'n_estimators': 5}\n",
      "0.483 + or -0.0 for the {'max_depth': 4, 'n_estimators': 10}\n",
      "0.483 + or -0.0 for the {'max_depth': 4, 'n_estimators': 50}\n",
      "0.483 + or -0.0 for the {'max_depth': 4, 'n_estimators': 100}\n",
      "0.483 + or -0.0 for the {'max_depth': 4, 'n_estimators': 250}\n",
      "0.483 + or -0.002 for the {'max_depth': 8, 'n_estimators': 5}\n",
      "0.483 + or -0.001 for the {'max_depth': 8, 'n_estimators': 10}\n",
      "0.483 + or -0.0 for the {'max_depth': 8, 'n_estimators': 50}\n",
      "0.483 + or -0.0 for the {'max_depth': 8, 'n_estimators': 100}\n",
      "0.483 + or -0.0 for the {'max_depth': 8, 'n_estimators': 250}\n",
      "0.49 + or -0.002 for the {'max_depth': 16, 'n_estimators': 5}\n",
      "0.488 + or -0.002 for the {'max_depth': 16, 'n_estimators': 10}\n",
      "0.484 + or -0.001 for the {'max_depth': 16, 'n_estimators': 50}\n",
      "0.483 + or -0.001 for the {'max_depth': 16, 'n_estimators': 100}\n",
      "0.483 + or -0.001 for the {'max_depth': 16, 'n_estimators': 250}\n",
      "0.496 + or -0.006 for the {'max_depth': 32, 'n_estimators': 5}\n",
      "0.498 + or -0.008 for the {'max_depth': 32, 'n_estimators': 10}\n",
      "0.493 + or -0.003 for the {'max_depth': 32, 'n_estimators': 50}\n",
      "0.491 + or -0.003 for the {'max_depth': 32, 'n_estimators': 100}\n",
      "0.488 + or -0.002 for the {'max_depth': 32, 'n_estimators': 250}\n",
      "0.508 + or -0.01 for the {'max_depth': 64, 'n_estimators': 5}\n",
      "0.514 + or -0.005 for the {'max_depth': 64, 'n_estimators': 10}\n",
      "0.513 + or -0.004 for the {'max_depth': 64, 'n_estimators': 50}\n",
      "0.509 + or -0.004 for the {'max_depth': 64, 'n_estimators': 100}\n",
      "0.505 + or -0.005 for the {'max_depth': 64, 'n_estimators': 250}\n"
     ]
    }
   ],
   "source": [
    "display(cv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qh8oXHVKQ3Fw"
   },
   "source": [
    "On relance notre modele avec les paramateres du grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "WIXxC-Ph1doB",
    "outputId": "8fdcb113-7d1c-413e-979a-8283004baed0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 51.8\n",
      "MSE:  1.6421895861148197\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rmfrclass = RandomForestClassifier(max_depth = 64,n_estimators = 10 )\n",
    "rmfrclass.fit(x_train_c, y_train_c)\n",
    "predrmfrclass = rmfrclass.predict(x_test_c)\n",
    "print(\"Score:\",round(accuracy_score(y_test_c,predrmfrclass)*100,2))\n",
    "print(\"MSE: \",mean_squared_error(y_test_c,predrmfrclass))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "saVzFd-JRGOS"
   },
   "source": [
    "#### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "KRBC9c5ieDh4",
    "outputId": "180fae85-c36b-4c3d-c21a-5bb32592ff18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 49.6\n",
      "MSE:  2.0493991989319094\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.svm import SVC\n",
    "svm = SVC(random_state=101)\n",
    "svm.fit(x_train_c,y_train_c)\n",
    "predsvm = svm.predict(x_test_c)\n",
    "print(\"Score:\",round(accuracy_score(y_test_c,predsvm)*100,2))\n",
    "print(\"MSE: \",mean_squared_error(y_test_c,predsvm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pWyRBvmH73zC"
   },
   "source": [
    "## Regression lineaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "IQ8isPDQ77x-",
    "outputId": "ceb4aedd-c0ff-41c3-f849-9b850c940034"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  0.596444694252513\n",
      "MSE:  0.5117956954363189\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "reg = LinearRegression()\n",
    "reg.fit(x_train_c,y_train_c)\n",
    "print(\"Score: \", reg.score(x_test_c, y_test_c))\n",
    "pred_lin_reg = reg.predict(x_test_c)\n",
    "print(\"MSE: \",mean_squared_error(y_test_c,pred_lin_reg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "YecSPxn0y2hq",
    "outputId": "a6202c6e-fecd-4d49-d023-22262a99d958"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.60503475]\n"
     ]
    }
   ],
   "source": [
    "#Suppos√© 2\n",
    "print(reg.predict(vect.transform([' \t1st time seattle delayed anniversary trip wanted stay nicer hotels room reminded holiday inn level hotel \tplain room extra pillows \tbathroom ordinary corian sink ordinary bathroom \troom higher floor looking freeway loud \treason earplugs sleep cd \tasked switch rooms told probably stay way stay 2 nights staying hotel different area town \tluggage room decided eat \tstopped concierge asked good place walk rudely told just walk area \tnot sure concierge doorman just sitting desk expected help \tdecided night hotel come day earlier happily said \tused club points crowne rooms maybe lousy experience opted leave pay room luxury hotel hotel 1000'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qlnHm9Qw-f0U"
   },
   "outputs": [],
   "source": [
    "#from sklearn import datasets,linear_model\n",
    "#from sklearn.model_selection import GridSearchCV\n",
    "#parameters = {'kernel':('linear', 'rbf')}\n",
    "#svc=linear_model.ARDRegression(n_iter=300,tol=0.001)\n",
    "#clf = GridSearchCV(svc, parameters, cv=5)\n",
    "#clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3FkOjnedlqwz"
   },
   "source": [
    "## Resume des differents modele de machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T3hk0QYYmaRB"
   },
   "source": [
    "#### Le linear SVC a la meilleure precision mais la regression lineaire nous donne le plus petit mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G8kEQqImmpOK"
   },
   "source": [
    "# Improve the model with Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 233
    },
    "colab_type": "code",
    "id": "9bnBeRAFf5_b",
    "outputId": "281aeb43-fc98-41f8-a883-82cc23b181d5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
      "[nltk_data]   Package treebank is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from keras import Sequential\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Lambda\n",
    "from keras.layers import LSTM\n",
    "import keras.backend as K\n",
    "\n",
    "import nltk\n",
    "nltk.download('treebank')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CvCGyTmmoPNF"
   },
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "htSO91UAm3Vp"
   },
   "outputs": [],
   "source": [
    "def create_dataset(num_words, max_text_len, data):\n",
    "  res = []\n",
    "  for i in tqdm(range(len(data))):\n",
    "    res.append([preprocess_text(data.iloc[i][\"reviews.text\"]), data.iloc[i][\"reviews.rating\"]])\n",
    "  inp, targ = zip(*res)\n",
    "  print(\"Tokenizing the data ...\")\n",
    "  tokenizer = keras.preprocessing.text.Tokenizer(num_words = num_words)\n",
    "  tokenizer.fit_on_texts([i[0] for i in inp])\n",
    "  tensor = [ tokenizer.texts_to_sequences(i)[0] for i in inp]\n",
    "  tensor = keras.preprocessing.sequence.pad_sequences(tensor, padding='post',   value=0, maxlen=max_text_len)\n",
    "  print(\"Splitting the data into train/val datasets (0.2) ...\")\n",
    "  input_tensor_train, input_tensor_test, target_tensor_train, target_tensor_test = train_test_split(tensor, targ, test_size=0.1)\n",
    "\n",
    "  return (input_tensor_train, np.array(target_tensor_train)-1), (input_tensor_test, target_tensor_test),  tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EgslIYBVoejH"
   },
   "source": [
    "## Hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cZwqkLrknIM_"
   },
   "outputs": [],
   "source": [
    "vocab_size = 5000\n",
    "embed_size = 300\n",
    "max_text_len = 200\n",
    "learning_rate = 0.001\n",
    "batch_size = 128\n",
    "n_epochs = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "9RBdUFoynNUs",
    "outputId": "8c6d037c-b441-474e-dd6e-78800e5bb061"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9982/9982 [00:17<00:00, 556.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing the data ...\n",
      "Splitting the data into train/val datasets (0.2) ...\n"
     ]
    }
   ],
   "source": [
    "train_set, test_set, dictionary = create_dataset(vocab_size, max_text_len, original_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DRgR6DhbotRj"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 275
    },
    "colab_type": "code",
    "id": "KgET9W9SnRTD",
    "outputId": "c5e1c40b-4426-4fb2-de1c-dc42774beac2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3239: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embed_size, input_shape=(max_text_len,), mask_zero=True))\n",
    "model.add(LSTM(512, return_sequences=True))\n",
    "model.add(LSTM(512, return_sequences=True))\n",
    "model.add(Lambda(lambda x : K.mean(x, axis=1)))\n",
    "model.add(Dense(256, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(100, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "#model.add(Dense(50, activation=\"relu\"))\n",
    "model.add(Dense(5, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pbiEV9tqnU8o"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "PiBSBjIlnm1b",
    "outputId": "83a0e936-ed49-491b-c91d-574c4ccdac6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "# Variable-length int sequences.\n",
    "query_input = tf.keras.Input(shape=(max_text_len,), dtype='int32')\n",
    "\n",
    "# Embedding lookup.\n",
    "token_embedding = tf.keras.layers.Embedding(vocab_size, embed_size)\n",
    "# Query embeddings of shape [batch_size, Tq, dimension].\n",
    "query_embeddings = token_embedding(query_input)\n",
    "# Value embeddings of shape [batch_size, Tv, dimension].\n",
    "value_embeddings = token_embedding(query_input)\n",
    "\n",
    "# CNN layer.\n",
    "cnn_layer = tf.keras.layers.Conv1D(\n",
    "    filters=100,\n",
    "    kernel_size=4,\n",
    "    # Use 'same' padding so outputs have the same shape as inputs.\n",
    "    padding='same')\n",
    "# Query encoding of shape [batch_size, Tq, filters].\n",
    "query_seq_encoding = cnn_layer(query_embeddings)\n",
    "# Value encoding of shape [batch_size, Tv, filters].\n",
    "value_seq_encoding = cnn_layer(value_embeddings)\n",
    "\n",
    "# Query-value attention of shape [batch_size, Tq, filters].\n",
    "query_value_attention_seq = tf.keras.layers.AdditiveAttention()(\n",
    "    [query_seq_encoding, value_seq_encoding])\n",
    "\n",
    "# Reduce over the sequence axis to produce encodings of shape\n",
    "# [batch_size, filters].\n",
    "query_encoding = tf.keras.layers.GlobalAveragePooling1D()(\n",
    "    query_seq_encoding)\n",
    "query_value_attention = tf.keras.layers.GlobalAveragePooling1D()(\n",
    "    query_value_attention_seq)\n",
    "\n",
    "fcn1 = tf.keras.layers.Dense(256)(query_value_attention)\n",
    "dropout1 = tf.keras.layers.Dropout(0.5)(fcn1)\n",
    "fcn2 = tf.keras.layers.Dense(100)(dropout1)\n",
    "dropout2 = tf.keras.layers.Dropout(0.2)(fcn2)\n",
    "\n",
    "output = tf.keras.layers.Dense(5, activation=\"softmax\")(dropout2)\n",
    "\n",
    "model = tf.keras.Model(query_input, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 544
    },
    "colab_type": "code",
    "id": "l8wUzeFBnoB2",
    "outputId": "63acb39c-d4a4-4fc0-c310-6e71d22f9d14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 200)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 200, 300)     1500000     input_1[0][0]                    \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 200, 100)     120100      embedding[0][0]                  \n",
      "                                                                 embedding[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "additive_attention (AdditiveAtt (None, 200, 100)     100         conv1d[0][0]                     \n",
      "                                                                 conv1d[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 100)          0           additive_attention[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          25856       global_average_pooling1d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 256)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 100)          25700       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 100)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 5)            505         dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,672,261\n",
      "Trainable params: 1,672,261\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8ZjsOjFlnsST"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EYzIrB6qnyDz"
   },
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer = optimizer, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "NLjBj16znzi4",
    "outputId": "57b797d7-65c2-4d05-eca1-cad4b039be18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6737 samples, validate on 2246 samples\n",
      "Epoch 1/4\n",
      "6737/6737 [==============================] - 25s 4ms/sample - loss: 1.2520 - acc: 0.4811 - val_loss: 1.0740 - val_acc: 0.5298\n",
      "Epoch 2/4\n",
      "6737/6737 [==============================] - 22s 3ms/sample - loss: 0.9344 - acc: 0.5877 - val_loss: 0.8996 - val_acc: 0.5988\n",
      "Epoch 3/4\n",
      "6737/6737 [==============================] - 22s 3ms/sample - loss: 0.7256 - acc: 0.6870 - val_loss: 0.9080 - val_acc: 0.6126\n",
      "Epoch 4/4\n",
      "6737/6737 [==============================] - 22s 3ms/sample - loss: 0.5725 - acc: 0.7613 - val_loss: 1.0282 - val_acc: 0.6224\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f71c538c748>"
      ]
     },
     "execution_count": 54,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import class_weight\n",
    "cw = class_weight.compute_class_weight('balanced'\n",
    "                                               ,np.unique(train_set[1])\n",
    "                                               ,train_set[1])\n",
    "model.fit(train_set[0], [train_set[1]], batch_size=batch_size, epochs = n_epochs, validation_split=0.25 )#,class_weight=dict(zip(np.unique(train_set[1]),cw)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RK9r50jfn2a3"
   },
   "outputs": [],
   "source": [
    " def evaluate(X_test):\n",
    "  y_pred = np.argmax(model.predict(X_test[0]), axis=-1)+1\n",
    "  y_pred = np.mean(np.equal(y_pred , X_test[1]))\n",
    "  return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "YzNTRbAvpj1P",
    "outputId": "00e38a94-d915-4b45-db3a-b656c532eb8c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5935935935935935"
      ]
     },
     "execution_count": 59,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6T9NMPxqauAw"
   },
   "source": [
    "## Evaluation du projet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZOXAuZNWatXC"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "6Yz_zDJmbAO5",
    "outputId": "766d4fe3-44d6-44d4-c48f-ecef1abe7cf0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0075135243438185\n",
      "Meilleur MSE avec Linear Regression :  0.5117956954363189\n"
     ]
    }
   ],
   "source": [
    "#here an example of the simplest possible model\n",
    "#take reviews in input and return ratings \n",
    "def my_random_model(reviews):\n",
    "  res = []\n",
    "  for review in reviews:\n",
    "      res.append(1+4*random.random()) #any real between [1;5]\n",
    "  return pd.DataFrame(res)\n",
    "\n",
    "eval_predicted = my_random_model(original_dataset['reviews.text'])\n",
    "print(mean_squared_error(round(eval_predicted),original_dataset['reviews.rating']))\n",
    "\n",
    "print(\"Meilleur MSE avec Linear Regression : \",mean_squared_error(y_test_c,pred_lin_reg))\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Projet_NLP_Version_Finale.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
